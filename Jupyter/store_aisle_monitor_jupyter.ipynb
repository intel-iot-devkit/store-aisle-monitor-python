{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MODEL = /opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml\n",
    "%env CPU_EXTENSION = /opt/intel/openvino/inference_engine/lib/intel64/libcpu_extension_sse4.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Store Aisle Monitor\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit person to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "import pathlib\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "from inference import Network\n",
    "\n",
    "CONFIG_FILE = '../resources/config.json'\n",
    "\n",
    "# Weightage/ratio to merge (for Heatmap) original frame and colorMap frame(sum of both should be 1)\n",
    "INITIAL_FRAME_WEIGHTAGE = 0.65\n",
    "COLORMAP_FRAME_WEIGHTAGE = 0.35\n",
    "\n",
    "# Weightage/ratio to merge (for integrated output) people count frame and colorMap frame(sum of both should be 1)\n",
    "P_COUNT_FRAME_WEIGHTAGE = 0.65\n",
    "COLORMAP_FRAME_WEIGHTAGE_1 = 0.35\n",
    "\n",
    "# Multiplication factor to compute time interval for uploading snapshots to the cloud\n",
    "MULTIPLICATION_FACTOR = 5\n",
    "\n",
    "# Azure Blob container name\n",
    "CONTAINER_NAME = 'store-aisle-monitor-snapshots'\n",
    "\n",
    "# To get current working directory\n",
    "CWD = os.getcwd()\n",
    "# Creates subdirectories to save output videos and snapshots\n",
    "pathlib.Path(CWD + '/output_snapshots/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def apply_time_stamp_and_save(image, people_count, upload_azure):\n",
    "    \"\"\"\n",
    "    Saves snapshots with timestamps.\n",
    "    \"\"\"\n",
    "    current_date_time = time.strftime(\"%y-%m-%d_%H:%M:%S\", time.gmtime())\n",
    "    file_name = current_date_time + \"_PCount_\" + str(people_count) + \".png\"\n",
    "    file_path = CWD + \"/output_snapshots/\"\n",
    "    local_file_name = \"output_\" + file_name\n",
    "    file_name = file_path + local_file_name\n",
    "    cv2.imwrite(file_name, image)\n",
    "    if upload_azure is 1:\n",
    "        upload_snapshot(file_path, local_file_name)\n",
    "\n",
    "\n",
    "def create_cloud_container(account_name, account_key):\n",
    "    \"\"\"\n",
    "    Creates a BlockBlobService container on cloud.\n",
    "    \"\"\"\n",
    "    global BLOCK_BLOB_SERVICE\n",
    "\n",
    "    # Create the BlockBlobService to call the Blob service for the storage account\n",
    "    BLOCK_BLOB_SERVICE = BlockBlobService(account_name, account_key)\n",
    "    # Create BlockBlobService container\n",
    "    BLOCK_BLOB_SERVICE.create_container(CONTAINER_NAME)\n",
    "    # Set the permission so that the blobs are public\n",
    "    BLOCK_BLOB_SERVICE.set_container_acl(CONTAINER_NAME, public_access=PublicAccess.Container)\n",
    "\n",
    "\n",
    "def upload_snapshot(file_path, local_file_name):\n",
    "    \"\"\"\n",
    "    Uploads snapshots to cloud storage container.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        full_path_to_file = file_path + local_file_name\n",
    "        print(\"\\nUploading to cloud storage as blob : \" + local_file_name)\n",
    "        # Upload the snapshot, with local_file_name as the blob name\n",
    "        BLOCK_BLOB_SERVICE.create_blob_from_path(CONTAINER_NAME, local_file_name, full_path_to_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def main():\n",
    "    global CONFIG_FILE\n",
    "    model_xml = (os.environ[\"MODEL\"])\n",
    "    device = os.environ['DEVICE'] if 'DEVICE' in os.environ.keys() else 'CPU'\n",
    "    cpu_extension = os.environ[\n",
    "        'CPU_EXTENSION'] if 'CPU_EXTENSION' in os.environ.keys() else None\n",
    "    try:\n",
    "        # Probability threshold for detections filtering\n",
    "        prob_threshold = float(os.environ['PROB_THRESHOLD'])\n",
    "    except KeyError:\n",
    "        prob_threshold = 0.5\n",
    "    try:\n",
    "        # Specify the azure storage name to upload results to cloud.\n",
    "        account_name = os.environ['ACCOUNT_NAME']\n",
    "    except:\n",
    "        account_name = None\n",
    "    try:\n",
    "        # Specify the azure storage key to upload results to cloud.\n",
    "        account_key = os.environ['ACCOUNT_KEY']\n",
    "    except:\n",
    "        account_key = None                \n",
    "\n",
    "    if account_name is \"\" or account_key is \"\":\n",
    "        print(\"Invalid account name or account key!\")\n",
    "        sys.exit(1)\n",
    "    elif account_name is not None and account_key is None:\n",
    "        print(\"Please provide account key using -ak option!\")\n",
    "        sys.exit(1)        \n",
    "    elif account_name is None and account_key is not None:\n",
    "        print(\"Please provide account name using -an option!\")\n",
    "        sys.exit(1) \n",
    "    elif account_name is None and account_key is None:\n",
    "        upload_azure = 0\n",
    "    else:\n",
    "        print(\"Uploading the results to Azure storage \\\"\"+ account_name+ \"\\\"\" )\n",
    "        upload_azure = 1\n",
    "        create_cloud_container(account_name, account_key)\n",
    "    assert os.path.isfile(CONFIG_FILE), \"{} file doesn't exist\".format(CONFIG_FILE)\n",
    "    config = json.loads(open(CONFIG_FILE).read())\n",
    "    for idx, item in enumerate(config['inputs']):\n",
    "        if item['video'].isdigit():\n",
    "            input_stream = int(item['video'])\n",
    "            cap = cv2.VideoCapture(input_stream)\n",
    "            if not cap.isOpened():\n",
    "                print(\"\\nCamera not plugged in... Exiting...\\n\")\n",
    "                sys.exit(0)\n",
    "        else:\n",
    "            input_stream = item['video']\n",
    "            cap = cv2.VideoCapture(input_stream)\n",
    "            if not cap.isOpened():\n",
    "                print(\"\\nUnable to open video file... Exiting...\\n\")\n",
    "                sys.exit(0)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    flag = os.environ['FLAG'] if 'FLAG' in os.environ.keys() else \"async\"\n",
    "    # Initialise the class\n",
    "    infer_network = Network()\n",
    "    # Load the network to IE plugin to get shape of input layer\n",
    "    n, c, h, w = infer_network.load_model(model_xml, device, 1, 1, 2, cpu_extension)[1]\n",
    "\n",
    "    print(\"To stop the execution press Esc button\")\n",
    "    initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = 1\n",
    "    accumulated_image = np.zeros((initial_h, initial_w), np.uint8)\n",
    "    mog = cv2.createBackgroundSubtractorMOG2()\n",
    "    ret, frame = cap.read()\n",
    "    cur_request_id = 0\n",
    "    next_request_id = 1\n",
    "    if flag == \"sync\":\n",
    "        print('Aplication running in Sync mode')\n",
    "        is_async_mode = False\n",
    "    else:\n",
    "        print('Aplication running in Async mode')\n",
    "        is_async_mode = True\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, next_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count = frame_count + 1\n",
    "        in_frame = cv2.resize(next_frame, (w, h))\n",
    "        # Change data layout from HWC to CHW\n",
    "        in_frame = in_frame.transpose((2, 0, 1))  \n",
    "        in_frame = in_frame.reshape((n, c, h, w))\n",
    "\n",
    "        # Start asynchronous inference for specified request.\n",
    "        inf_start = time.time()\n",
    "        if is_async_mode:\n",
    "            infer_network.exec_net(next_request_id, in_frame)\n",
    "        else:\n",
    "            infer_network.exec_net(cur_request_id, in_frame)\n",
    "\n",
    "        # Wait for the result\n",
    "        if infer_network.wait(cur_request_id) == 0:\n",
    "            det_time = time.time() - inf_start\n",
    "            people_count = 0\n",
    "\n",
    "            # Converting to Grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Remove the background\n",
    "            fgbgmask = mog.apply(gray)\n",
    "\n",
    "            # Thresholding the image\n",
    "            thresh = 2\n",
    "            max_value = 2\n",
    "            threshold_image = cv2.threshold(fgbgmask, thresh, max_value,\n",
    "                                                          cv2.THRESH_BINARY)[1]\n",
    "            # Adding to the accumulated image\n",
    "            accumulated_image = cv2.add(threshold_image, accumulated_image)\n",
    "            colormap_image = cv2.applyColorMap(accumulated_image, cv2.COLORMAP_HOT)\n",
    "\n",
    "            # Results of the output layer of the network\n",
    "            res = infer_network.get_output(cur_request_id)\n",
    "            for obj in res[0][0]:\n",
    "                # Draw only objects when probability more than specified threshold\n",
    "                if obj[2] > prob_threshold:\n",
    "                    xmin = int(obj[3] * initial_w)\n",
    "                    ymin = int(obj[4] * initial_h)\n",
    "                    xmax = int(obj[5] * initial_w)\n",
    "                    ymax = int(obj[6] * initial_h)\n",
    "                    class_id = int(obj[1])\n",
    "                    # Draw bounding box\n",
    "                    color = (min(class_id * 12.5, 255), min(class_id * 7, 255),\n",
    "                                  min(class_id * 5, 255))\n",
    "                    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "                    people_count = people_count + 1\n",
    "\n",
    "            people_count_message = \"People Count : \" + str(people_count)\n",
    "            inf_time_message = \"Inference time: N\\A for async mode\" if is_async_mode else \\\n",
    "            \"Inference time: {:.3f} ms\".format(det_time * 1000)\n",
    "            cv2.putText(frame, inf_time_message, (15, 25), cv2.FONT_HERSHEY_COMPLEX, 1,\n",
    "                             (255, 255, 255), 2)\n",
    "            cv2.putText(frame, people_count_message, (15, 65), cv2.FONT_HERSHEY_COMPLEX, 1,\n",
    "                             (255, 255, 255), 2)\n",
    "            final_result_overlay = cv2.addWeighted(frame, P_COUNT_FRAME_WEIGHTAGE,\n",
    "                                                        colormap_image,\n",
    "                                                        COLORMAP_FRAME_WEIGHTAGE_1, 0)\n",
    "            cv2.imshow(\"Detection Results\", final_result_overlay)\n",
    "\n",
    "            time_interval = MULTIPLICATION_FACTOR * fps\n",
    "            if frame_count % time_interval == 0:\n",
    "                apply_time_stamp_and_save(final_result_overlay, people_count, upload_azure)\n",
    "\n",
    "        frame = next_frame\n",
    "        if is_async_mode:\n",
    "            cur_request_id, next_request_id = next_request_id, cur_request_id\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    infer_network.clean()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main() or 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
